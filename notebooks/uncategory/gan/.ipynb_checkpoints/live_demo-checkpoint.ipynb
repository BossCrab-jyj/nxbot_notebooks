{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对抗生成神经网络生成数字或字母\n",
    "\n",
    "## 1.导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from nxbot import Robot,event,bgr8_to_jpeg\n",
    "import cv2\n",
    "import threading\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.创建可视化窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像生成图像显示窗口\n",
    "image_widget = widgets.Image(format='jpeg')\n",
    "# 模型训练结果显示窗口\n",
    "result_info = widgets.Textarea(\n",
    "    placeholder='NXROBO',\n",
    "    description='训练结果：',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--number_or_letter\", type=str, default='number', help=\"生成数字：number，生成字母：letters\")\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"训练次数\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"每次训练的图片数量\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam优化器学习率\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam优化器动量衰减率\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"aadam优化器动量衰减率\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=4, help=\"设定cpu进程数量，用于图片加载\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"经过神经网络提取的特征向量大小\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"图片大小\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"单通道图片\")\n",
    "parser.add_argument(\"--save\", type=bool, default=False, help=\"是否保存图片，图片保存在images文件夹下\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=2, help=\"每sample_interval个batch_size保存一次图片\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.定义生成网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.number_or_letter=='number':\n",
    "    # 数字类别数量\n",
    "    num_classes=10\n",
    "else:\n",
    "    # 字母类别数量，26个字母加空字符串\n",
    "    num_classes=27\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)  # （weights,mean,std）\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)  # 初始化bias\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(num_classes, opt.latent_dim)\n",
    "        self.init_size = opt.img_size // 4  # Initial size before upsampling初始化上采样的size大小\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)) \n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8), # 只取其中的80%用于更新计算均值与方差\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # self.label_emb(labels)：当前batch中每个类别使用指定个标量表示，shape为：[batchsize，opt.latent_dim]\n",
    "        # 这里表示self.label_emb(labels) = [batchsize，opt.latent_dim]× noise = [batchsize,opt.latent_dim]\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        # 将 gen_input=[batch_size,opt.latent_dim]变为 out=[batch_size,128 * self.init_size ** 2]\n",
    "        out = self.l1(gen_input)\n",
    "        # 将 out=[batch_size,128 * self.init_size ** 2] 变为 out=[batch_size,128，self.init_size, self.init_size] = [batch_size,128，8,8]\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        # 开始卷积，上采样变为[100,1,32,32]\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.定义决策网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "\n",
    "        # Output layers,sigmoid函数预测图片是真图片还是假图片。\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        # 预测图片的类别\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, num_classes), nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "\n",
    "if opt.number_or_letter=='number':\n",
    "    data_dir = \"../../../models/local/datasets/mnist\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    dataset = datasets.MNIST(\n",
    "        data_dir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])] # image=(image-mean)/std\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "elif opt.number_or_letter=='letters':\n",
    "    data_dir = \"../../../models/local/datasets/emnist\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    dataset = datasets.EMNIST(\n",
    "            data_dir,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            split = 'letters',\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])] # image=(image-mean)/std\n",
    "            ),\n",
    "        )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.定义神经网络所需参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化网络\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 定义损失函数\n",
    "adversarial_loss = torch.nn.BCELoss() # 预测概率损失函数，对抗网络损失函数BCELoss：Loss = -w * [p * log(r) + (1-r) * log(1-r)]\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss() # 类别损失函数\n",
    "\n",
    "# 转到cuda\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# 初始化模型中的所有参数\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "# Optimizers，每个网络有自己单独的优化器\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "# 数据类型定义\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示生成的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    # 噪声样本\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))  # np.random.normal()正太分布\n",
    "    # 拼接图片\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    # 如果需要保存图片\n",
    "    if opt.save:\n",
    "        save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "    # 保存当前图片作为显示\n",
    "    save_image(gen_imgs.data, \"result.png\", nrow=n_row, normalize=True)\n",
    "    # 显示生成的图片\n",
    "    image_widget.value = bgr8_to_jpeg(cv2.imread(\"result.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义对抗生成网络训练函数\n",
    "一开始，生成器和判别器的水平都很差，因为两者都是随机初始化的。训练的步骤分两步交替进行：\n",
    "\n",
    "* 第一步是训练判别器D(只修改判别器的参数，固定生成器)，目标是把真图片和假图片区分开\n",
    "* 第二步是训练生成器(只修改生成器的参数，固定判别器)，为的是生成的假图片能够被判别器判别为真图片\n",
    " \n",
    "这两步交替进行，为的是生成的假图片能够被判别为真图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    result_info.value = '正在加载，请稍后。。。'\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "            batch_size = imgs.shape[0]\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            # 真实的正标签概率为1\n",
    "            valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "            # 真实的假标签概率为0\n",
    "            fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "            # Configure input\n",
    "            real_imgs = Variable(imgs.type(FloatTensor))\n",
    "            labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            # 生成器梯度归零\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Sample noise and labels as generator input\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "            gen_labels = Variable(LongTensor(np.random.randint(0, num_classes, batch_size)))\n",
    "\n",
    "            # 生成网络通过一组随机噪声与给定的标签生成出一张图片\n",
    "            gen_imgs = generator(z, gen_labels)\n",
    "            \n",
    "            # 鉴别网络对生成的图片进行预测，结果为预测的类别和预测的类别的概率\n",
    "            validity, pred_label = discriminator(gen_imgs)\n",
    "            \n",
    "            # 鉴别网络预测生成的图片的类别概率与1（真图片的概率）的误差，预测的标签与生成的标签之间的误差\n",
    "            g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "            \n",
    "            # 反向传播\n",
    "            g_loss.backward()\n",
    "            # 更新生成网络的参数\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator 训练裁判（鉴别器）\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # 在更新决策网络时，需要对真实图片预测结果为真，对生成图片预测结果为假\n",
    "            # 鉴别网络对真实图片进行预测， 结果为预测的类别和预测的类别的概率\n",
    "            real_pred, real_aux = discriminator(real_imgs)\n",
    "            \n",
    "            # 真实样本经过鉴别网络后预测的类别概率与真实类别概率（1）的损失+真实样本经过鉴别网络后预测的类别与真正的标签损失\n",
    "            d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "            # 对于生成的图片，在训练判别器时，我们希望判别器输出为0；而在训练生成器时，我们希望判别器输出为1，这样实现判别器和生成器互相对抗提升\n",
    "            # 鉴别网络对创造出来的图片的预测，需要对生成器生成的图片用detach()操作进行计算图截断，避免反向传播将梯度传到生成器中\n",
    "            fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "            # （预先给定的假图片的概率，经过鉴别网络预测的图片概率的loss）+（预先给定的假图片的类别，经过鉴别网络预测的图片类别的loss）\n",
    "            d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "            # 计算真实图片的loss+生成图片的loss\n",
    "            # 真实的图片经过检测器会得到对应的类别与类别概率，然后与真实的类别与类别概率（100%，这是真图片）进行计算loss，\n",
    "            # 生成的图片经过检测器会得到对应的类别与类别概率，然后与生成的类别与概率（0%，这是假图片）进行计算loss，\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "            # 计算决策网络的准确率\n",
    "            pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "            gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "            d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "            \n",
    "            # 更新决策网络参数\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            batches_done = epoch * len(dataloader) + i\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                sample_image(n_row=num_classes, batches_done=batches_done)\n",
    "            # 打印结果\n",
    "            result_info.value =  \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"% (epoch, \n",
    "                                  opt.n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.开始训练，并显示生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process1 = threading.Thread(target=train,)\n",
    "process1.start()\n",
    "display(result_info)\n",
    "display(image_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
