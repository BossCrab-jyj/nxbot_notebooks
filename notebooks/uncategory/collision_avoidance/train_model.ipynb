{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 避障模型训练\n",
    "通过对上一个示例演示学习，我们掌握了如何收集图片并保存在文件夹中，接下来就需要我们通过神经网络来训练出模型了。\n",
    "> 首先还是需要我们导入训练所需要的模块：\n",
    "1. torch:Pytorch是一个方便于初学者学习的深度学习框架，包含有torch和torchvision这两个重要的模块，目前比较流行的深度学习框架有tensorflow，caffe等。\n",
    "2. torchvision:多用于数据处理和模型处理的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据预处理\n",
    "现在，我们使用“torchvision”模块里“dataset.ImageFolder()”的方法来创建一个图片数据集。\n",
    "1. 放入我们之前收集好的图片文件夹“dataset”\n",
    "2. 通过“torchvision.transforms”对图片数据进行一系列处理，预处理后的数据有助于模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'datasets',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "class_idx = dataset.class_to_idx\n",
    "print('数据标签与对应的索引',class_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.将数据集分割为训练集和测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们通过“torch.utils.data.random_split()”方法将数据集拆分为\"training\"和\"test\"数据集。\n",
    "测试集将用于验证我们通过训练集训练的模型的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "valid_percente = 0.2\n",
    "num_valid = int(len(dataset)*valid_percente)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_valid, num_valid])\n",
    "\n",
    "num_train_dataset = len(train_dataset)\n",
    "num_test_dataset = len(test_dataset)\n",
    "print('训练数据集图片数量：',num_train_dataset)\n",
    "print('测试数据集图片数量：',num_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.创建数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载器有利于节省计算资源，同时也会提高模型的表现力。\n",
    "1. 通过“torch.utils.data.DataLoader()”方法来创建数据加载器。\n",
    "2. 里面主要包括数据集“train_dataset”或者“test_dataset”；\n",
    "3. 每一次输入神经网络的图片数量:“batch_size”；\n",
    "4. 是否打乱图片的顺序:“shuffle”；使用芯片的核心数量:“num_workers”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.定义神经网络\n",
    "“torchvision.models”提供了很多网络结构和预训练模型供我们使用。这里我们使用“alexnet”预训练模型\n",
    ">“迁移学习”：当“pretrained=True”表示我们会运用“迁移学习”进行训练，我们将一个针对数百万张图像进行训练得到的预训练模型，再结合我们自己的数据进行训练，这样会让我们使用较少的数据就能让模型获得很好的效果，节约很多数据和训练时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“alexnet”的预训练模型是通过1000个类别数据集训练得到的，但是我们的数据集只有两个类别！因此我们将模型的分类层（“alexnet”的分类层在第6层网络，不同的网络，分类层的位置也不同。）改为2个类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将模型转移到GPU上执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.训练神经网络\n",
    "\n",
    "接下来就可以通过下面的代码，来训练我们的模型了。\n",
    "\n",
    "1. 我们将模型训练迭代（epoch）10次，每一次迭代表示模型在整个训练数据集上训练一次，这里表示模型在整个训练数据集上学习了50次；\n",
    "2. 每训练完一个epoch，就通过我们的测试数据集来对我们的模型进行验证，你可以在训练的时候看到训练的结果；\n",
    "3. 最后我们把准确率最高的模型保存下来，训练完成之后，我们可以左边的文件管理器看到一个模型文件“ best_model_custom.pth”。\n",
    "\n",
    "小提示：运行下面的代码会需要一段时间来进行训练，请耐心等待！训练时间会根据你的照片数量，网络结构选择，epoch等因素来决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 设置训练迭代次数\n",
    "NUM_EPOCHS = 10\n",
    "# 设置模型保存路径\n",
    "model_path = r'students_models/best_model_custom.pth'\n",
    "# 设置优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# 开始迭代训练\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    batch = 0\n",
    "    # 初始化训练参数\n",
    "    best_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    # 初始化测试参数\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "    # 模型训练\n",
    "    model.train()\n",
    "    for images, labels in iter(train_loader):\n",
    "        # 选择设备将“图片”和“标签”输入模型中\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 初始化梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 模型前向传播\n",
    "        outputs = model(images)\n",
    "        # 通过交叉熵求出模型预测的结果与真实“标签”之间的误差值loss\n",
    "        tr_loss = F.cross_entropy(outputs, labels)\n",
    "        # 反向传播，通过loss对模型参数进行求导更新参数\n",
    "        tr_loss.backward()\n",
    "        # 使用优化器对模型参数进行更新\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += tr_loss.item() * images.size(0)\n",
    "\n",
    "        _, predict = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(labels.data == predict)\n",
    "\n",
    "    train_loss = train_loss / num_train_dataset\n",
    "    train_acc = train_corrects.item() / num_train_dataset\n",
    "    # 对测试集进行评估\n",
    "    model.eval()\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            # 前向传播得到预测结果\n",
    "            outputs = model(images)\n",
    "            _, predict = torch.max(outputs, 1)\n",
    "            t_loss = F.cross_entropy(outputs, labels)\n",
    "            test_loss += t_loss.item() * images.size(0)\n",
    "\n",
    "            # 记录预测失败的数量\n",
    "            test_corrects += torch.sum(labels.data == predict)\n",
    "\n",
    "    test_loss = test_loss / num_test_dataset\n",
    "    test_acc = test_corrects.item() / num_test_dataset\n",
    "\n",
    "    print('epoch={}'.format(epoch + 1))\n",
    "    print('训练数据集准确率为：{:.2%}，误差为：{}'.format(train_acc, train_loss))\n",
    "    print('测试数据集准确率为：{:.2%}, 误差为：{}'.format(test_acc, test_loss))\n",
    "\n",
    "    if test_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        best_accuracy = test_acc\n",
    "print('训练完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
