{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器人目标追踪\n",
    "\n",
    "在这个示例中，我们将展示如何使用机器人进行对象跟踪!我们将使用一个在[COCO 数据集](http://cocodataset.org)上进行预训练的模型来检测90个不同的物体和1个背景类别。\n",
    "包括：人 (索引 0),杯子 (索引 47)...等\n",
    "\n",
    "目标检测区别于我们之前对整个图片的图像识别，而且单一的图像识别他的标签只有一个，比如之前学习的“避障”训练，他的标签就只有“有障碍”或者“无障碍”这样一个类别标签，然而目标检测除了类别标签之外，还有每个类别在图片里的位置和大小信息，而且每张图片还可能有多个类别和位置信息。当我们通过摄像头来检测时目标检测可以识别出图片里它所认识的所有物体并且会用一个矩形框把物体框在里面，在接下来的学习中你可以清楚的看到！你可以在“coco_index.txt”文件中查看所有的类别和对应的索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入我们需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************\n",
      "*                NXROBO - 机器人SDK                     *\n",
      "*       (c) 2019 J.Xiao <jie.xiao@nxrobo.com>          *\n",
      "*                https://www.nxrobo.com                *\n",
      "********************************************************\n",
      "               当前SDK版本: 0.3.2.dev\n",
      "            如需退出，可以按 Ctrl-C 组合键\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# from __future__ import division\n",
    "from nxbot import Robot,event,bgr8_to_jpeg\n",
    "\n",
    "from modules.models import *\n",
    "from modules.utils.util import *\n",
    "from modules.utils.datasets import *\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import threading\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from traitlets.config.configurable import Configurable\n",
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(Dachbot_model_path='yolov3_ckpt_10.pth', Dbot_model_path='auto_drive.engine', class_path='modules/data/custom/classes.names', conf_thres=0.8, img_size=416, model_def='modules/config/auto_drive.cfg', nms_thres=0.2)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_def\", type=str, default=\"modules/config/auto_drive.cfg\", help=\"yolov3-tiny网络结构配置文件\")\n",
    "parser.add_argument(\"--Dachbot_model_path\", type=str, default=\"yolov3_ckpt_10.pth\", help=\"Dachbot模型文件\")\n",
    "parser.add_argument(\"--Dbot_model_path\", type=str, default=\"auto_drive.engine\", help=\"Dbot模型文件\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"modules/data/custom/classes.names\", help=\"检测类别的所有种类\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.8, help=\"物体置信度\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.2, help=\"非极大抑制阈值\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"网络接收图片大小\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dachbot\n"
     ]
    }
   ],
   "source": [
    "# 实例化机器人对象\n",
    "rbt = Robot()\n",
    "# 机器人名字\n",
    "rbt_name = rbt.name\n",
    "print(rbt_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 如果是dachbot可以使用更准确的模型\n",
    "if rbt_name=='dachbot':\n",
    "    model = Darknet(opt.model_def, img_size=opt.img_size, TensorRT=False, Half=False).to(device).half()\n",
    "    # 权重加载\n",
    "#     model.load_darknet_weights(opt.Dachbot_model_path)\n",
    "    model.load_state_dict(torch.load(opt.Dachbot_model_path))\n",
    "    # Set in evaluation mode 前向推理时候会忽略 BatchNormalization 和 Dropout\n",
    "    model.eval()\n",
    "    \n",
    "# 如果是dbot可以使用速度更快的模型    \n",
    "elif rbt_name=='dbot':\n",
    "    model_backbone = Darknet_Backbone(opt.model_def, img_size=opt.img_size).to(device).half()\n",
    "    model = TRTModule()\n",
    "    model.load_state_dict(torch.load(opt.Dbot_model_path))\n",
    "    yolo_head = YOLOHead(config_path=opt.model_def)\n",
    "    \n",
    "# 提取可以识别的类别\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.创建可视化窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg')\n",
    "depth_image_widget = widgets.Image(format='jpeg')\n",
    "speed_widget = widgets.FloatSlider(value=0.0, min=0.0, step=0.01, max=0.5, description='运行速度')\n",
    "turn_gain_widget = widgets.FloatSlider(value=1.6, min=0.0, step=0.01, max=3.0, description='转向增益')\n",
    "turn_dgain_widget = widgets.FloatSlider(value=0.03, min=0.0, step=0.01, max=5.0, description='回正微调')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='方向')\n",
    "depth_slider = ipywidgets.FloatSlider(min=0.0, max=10000.0, description='深度值')\n",
    "state_info = widgets.Textarea(\n",
    "    placeholder='NXROBO',\n",
    "    description='当前状态',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.定义目标检测\n",
    "在这里我们将让机器人识别出它所看到的所有物体，并且判断距离图像中心点最近的物体是否与我们设定的目标物体一致（我们默认的是索引1，代表跟踪的目标是人），如果是设定目标，就跟着目标走，并根据物体再图像的位置让机器人判断左转还是右转。\n",
    "\n",
    "### 5.1.计算识别的物体的中心点坐标相对于图片中心点的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_center(label):\n",
    "    dis_x = 0.5-((label[2] - label[0])/2+label[0])\n",
    "    return dis_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.在检测到的物体中找出与中心点最近的那一个物体作为目标物体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_line(matching_labels):\n",
    "    closest_det = None\n",
    "    update_det = None\n",
    "    for det in matching_labels:\n",
    "        if det[3]<120:\n",
    "            if ((det[3] - det[1])/(det[2] - det[0]))>1.2:\n",
    "                if closest_det is None:\n",
    "                    closest_det = det\n",
    "                # 找出y坐标最大的 line\n",
    "                elif det[3]>closest_det[3]:\n",
    "                    closest_det = det\n",
    "        else:\n",
    "            if closest_det is None:\n",
    "                closest_det = det\n",
    "            elif det[3]>closest_det[3]:\n",
    "                closest_det = det\n",
    "    return closest_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = np.array(Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)))\n",
    "    imgTensor = transforms.ToTensor()(image)\n",
    "    imgTensor, _ = pad_to_square(imgTensor, 0)\n",
    "    imgTensor = resize(imgTensor, 416)\n",
    "    imgTensor = imgTensor.unsqueeze(0)\n",
    "    imgTensor = Variable(imgTensor.type(Tensor)).half()\n",
    "    return imgTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.检测模型是否能正常运行\n",
    "\n",
    "我们通过numpy创建与我们将要预测的图片格式一致的形状为（416，416，3）的数组，这里我们创建的全为1的数组将这个数组经过预处理再将数据放入模型中，如果能运行通过说明模型可以正常使用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img_data = np.ones([416, 416, 3],np.uint8)\n",
    "    if rbt_name=='dachbot':\n",
    "        model(preprocess(img_data)).detach().half().cpu().numpy().flatten()\n",
    "    elif rbt_name=='dbot':\n",
    "        model(preprocess(img_data))\n",
    "except:\n",
    "    print('请检查模型是否正确')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.打开摄像头深度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_state(box_w, box_h, x1, y2, label_name, signal_dict, max_signal_size, max_classes):\n",
    "    box_size = box_w*box_h\n",
    "    if label_name == 'aobing':\n",
    "        if box_size>3000:\n",
    "            signal_dict['aobing']+=1\n",
    "\n",
    "    elif label_name == 'nezha':\n",
    "        if box_size>3000:\n",
    "            signal_dict['nezha']+=1\n",
    "\n",
    "    elif label_name == 'zebra_crossing':\n",
    "        signal_dict['zebra_crossing_y']= y2\n",
    "        if abs(150-box_w/2+x1)<80 and box_w/box_h>1.5:\n",
    "            signal_dict['zebra_crossing']+=1\n",
    "    else:\n",
    "        \n",
    "        if label_name == 'car_red' or label_name == 'car_red_yellow' or label_name == 'car_green' or label_name == 'car_yellow':\n",
    "            if box_size>2000:\n",
    "                if label_name == 'car_red':\n",
    "                    signal_dict['car_red']+=1\n",
    "                elif label_name == 'car_red_yellow':\n",
    "                    signal_dict['car_red_yellow']+=1\n",
    "                elif label_name == 'car_green':\n",
    "                    signal_dict['car_green']+=1\n",
    "                elif label_name == 'car_yellow':\n",
    "                    signal_dict['car_yellow']+=1\n",
    "        else:\n",
    "            if box_size>3500:\n",
    "                if box_size>max_signal_size:\n",
    "                    max_signal_size = box_size\n",
    "                    max_classes = label_name\n",
    "                if max_classes is not None:\n",
    "                    if max_classes == 'forward':\n",
    "                        signal_dict['forward']+=1\n",
    "                    elif max_classes == 'left':\n",
    "                        signal_dict['left']+=1\n",
    "                    elif max_classes == 'right':\n",
    "                        signal_dict['right']+=1\n",
    "                    elif max_classes == 'turn':\n",
    "                        signal_dict['turn']+=1\n",
    "                    elif max_classes == 'stop':\n",
    "                        signal_dict['stop']+=1\n",
    "    return signal_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.定义图像检测\n",
    "在这里我们将通过目标检测模型进行检测，检测出图像中的所有物体，并将所有物体用矩形框将物体框出来，然后在所有物体中找出距离图像中心点最近的物体作为目标物体，如果没有找到目标就停止，如果找到目标机器人就像目标移动，然后根据目标与图像中心点的距离计算出机器人旋转的相对角度，让机器人跟着你走。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化列表，用于存放识别结果\n",
    "all_pred=[]\n",
    "# 随机选择颜色\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype=\"uint8\")\n",
    "\n",
    "init_state = {'lights_off':0,'car_red':0,'car_yellow':0,'car_green':0,'car_red_yellow':0,\n",
    "              'pedestrian_red':0,'pedestrian_green':0,'nezha':0,'aobing':0,'line':0,'zebra_crossing':0,\n",
    "              'zebra_crossing_y':0, 'forward':0,'left':0,'right':0,'turn':0,'stop':0}\n",
    "\n",
    "\n",
    "global signal_dict\n",
    "signal_dict = init_state\n",
    "def prediction():\n",
    "    global detect_flag\n",
    "    detect_flag = True\n",
    "    \n",
    "    global matching_line\n",
    "    matching_line = None\n",
    "    \n",
    "    while detect_flag:\n",
    "        \n",
    "        global signal_dict\n",
    "        time.sleep(0.01)\n",
    "        origin_img = rbt.camera.read()\n",
    "        \n",
    "        detections = None\n",
    "        if origin_img is not None:\n",
    "            # 对图像数据进行预处理\n",
    "            imgTensor = preprocess(origin_img)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 将图像数据放入模型进行预测\n",
    "                outputs = model(imgTensor)\n",
    "                # 如果是dbot采用另外一种方法\n",
    "                if rbt_name=='dbot':\n",
    "                    outputs = yolo_head(outputs)\n",
    "                # 非极大抑制筛选更加合适的候选框\n",
    "                outputs = non_max_suppression(outputs, opt.conf_thres, opt.nms_thres)\n",
    "\n",
    "            all_pred.clear()\n",
    "            # 如果检测到类别就将结果放在all_pred列表中\n",
    "            if outputs is not None: \n",
    "                all_pred.extend(outputs)\n",
    "\n",
    "            if len(all_pred):\n",
    "                # 将所有识别结果在图像中标注出来\n",
    "                line_list = []\n",
    "                aobing_list = []\n",
    "                nezha_list = []\n",
    "                max_zebra_crossing = 0\n",
    "                max_signal_size = 0\n",
    "                max_classes = None\n",
    "                for outputs in all_pred:\n",
    "                    if outputs is not None:\n",
    "                        # 对预测类别框进行缩放\n",
    "                        detections = rescale_boxes(outputs, opt.img_size, origin_img.shape[:2])\n",
    "                        # 在图像上框出对应类别\n",
    "                        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                            label_name = classes[int(cls_pred)]\n",
    "                            if label_name!='line':\n",
    "                                box_w = x2 - x1\n",
    "                                box_h = y2 - y1\n",
    "                                color = [int(c) for c in colors[int(cls_pred)]]\n",
    "                                origin_img = cv2.rectangle(origin_img, (x1, y1 + box_h), (x2, y1), color, 2)\n",
    "                                cv2.putText(origin_img, label_name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                                cv2.putText(origin_img, str(\"%.2f\" % float(conf)), (x2, y2 - box_h), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                            color, 2)\n",
    "                                # 记录识别到的物体\n",
    "                                signal_dict = change_state(box_w, box_h, x1, y2, label_name, signal_dict, max_signal_size, max_classes)\n",
    "                                    \n",
    "                        line_list = [d for d in detections if classes[int(d[6])] == 'line']\n",
    "                        aobing_list = [d for d in detections if classes[int(d[6])] == 'aobing']\n",
    "                        nezha_list = [d for d in detections if classes[int(d[6])] == 'nezha']\n",
    "                        \n",
    "                if aobing_list==[]:\n",
    "                    signal_dict['aobing']=0\n",
    "                if nezha_list==[]:\n",
    "                    signal_dict['nezha']=0\n",
    "                if line_list != []:\n",
    "                    # 找出跟踪的那一条line\n",
    "                    matching_line = closest_line(line_list)\n",
    "                    if matching_line is not None:\n",
    "                        # 用红色标记标记目标line\n",
    "                        cv2.rectangle(origin_img, (matching_line[0], matching_line[1] + (matching_line[3]-matching_line[1])), \n",
    "                                                   (matching_line[2], matching_line[1]), (0,0,255), 2)\n",
    "\n",
    "                        \n",
    "            origin_img = cv2.resize(origin_img, (320, 240), interpolation=cv2.INTER_CUBIC)\n",
    "            image_widget.value=bgr8_to_jpeg(origin_img)\n",
    "\n",
    "# 创建线程\n",
    "process1 = threading.Thread(target=prediction,)\n",
    "# 启动线程\n",
    "process1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global depth\n",
    "depth = 0\n",
    "def on_new_depth(evt):\n",
    "    depth_frame = np.asanyarray(evt.dict['data'].get_data())\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_frame, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    depth_colormap = cv2.resize(depth_colormap, (320,240))\n",
    "    depth_image_widget.value = bgr8_to_jpeg(depth_colormap)\n",
    "    \n",
    "    global depth\n",
    "    depth = evt.dict['data'].get_distance(310, 80)\n",
    "    if depth ==0:\n",
    "        depth = evt.dict['data'].get_distance(330, 85)\n",
    "    depth_slider.value = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global speech_word\n",
    "speech_word=None\n",
    "\n",
    "def rbt_move():\n",
    "    last_steering = 0\n",
    "    no_line = 0\n",
    "    steering = 0\n",
    "    rise_head = 0\n",
    "    num_line = 0\n",
    "    global move_robot\n",
    "    move_robot=True\n",
    "    robot_state = {'road_following':True, 'signal_detection':False}\n",
    "    first_time = time.time()\n",
    "    speech_once = 0\n",
    "    global speech_word\n",
    "    speech_word=None\n",
    "    while move_robot:\n",
    "        time.sleep(0.01)\n",
    "        global matching_line\n",
    "        global signal_dict\n",
    "        global depth\n",
    "        speech_word=None\n",
    "        if depth != 0:\n",
    "            if depth>0.3:\n",
    "                if signal_dict['nezha']>1:\n",
    "                    state_info.value = '看到哪吒'\n",
    "                    speech_word = '发现哪吒在前方'\n",
    "                    rbt.base.move(0,0,0)\n",
    "                    robot_state['road_following'] = False\n",
    "                else:\n",
    "                    speech_once=0\n",
    "                    robot_state['road_following'] = True\n",
    "\n",
    "                if signal_dict['aobing']>1:\n",
    "                    state_info.value = '看到鳌丙'\n",
    "                    speech_word = '发现鳌丙在前方'\n",
    "                    rbt.base.move(0,0,0)\n",
    "                    robot_state['road_following'] = False\n",
    "                else:\n",
    "                    speech_once=0\n",
    "                    robot_state['road_following'] = True\n",
    "\n",
    "                if signal_dict['zebra_crossing']>3 and signal_dict['zebra_crossing_y']>280:\n",
    "                    robot_state['road_following'] = False\n",
    "                    if (time.time()-first_time)>6:\n",
    "                        state_info.value = '发现斑马线'\n",
    "                        speech_word = '发现斑马线'\n",
    "                        robot_state['road_following'] = False\n",
    "                        robot_state['signal_detection'] = True\n",
    "                        signal_dict['zebra_crossing']=0\n",
    "                        rise_head = 0\n",
    "                        num_line = 0\n",
    "                        rbt.base.move(0,0,0)\n",
    "                    else:\n",
    "                        speech_once=0\n",
    "                        signal_dict['zebra_crossing']=0\n",
    "                        signal_dict['zebra_crossing_y']=0\n",
    "                else:\n",
    "                    robot_state['road_following'] = True\n",
    "\n",
    "                if robot_state['road_following']==True and robot_state['signal_detection']==False:\n",
    "                    if matching_line is not None:\n",
    "                        target_line = matching_line/300\n",
    "                        state_info.value = '找到line，正常行驶'\n",
    "                        # 计算line的x轴中心点\n",
    "                        distance_x = detection_center(target_line)\n",
    "                        # 根据距离计算转向值\n",
    "                        steering = distance_x*turn_gain_widget.value+0.1\n",
    "                        steering = steering - (steering + last_steering)*turn_dgain_widget.value\n",
    "                        steering_slider.value = -steering\n",
    "                        speed = speed_widget.value\n",
    "                        rbt.base.move(speed, 0, steering)\n",
    "                        last_steering = steering\n",
    "                        no_line=0\n",
    "                    else:\n",
    "                        no_line+=1\n",
    "                        if no_line>150:\n",
    "                            state_info.value = '没有找到line，停止'\n",
    "                            rbt.base.move(0,0,0)\n",
    "                        else:\n",
    "                            state_info.value = '继续行驶'\n",
    "                            speed = speed_widget.value\n",
    "                            rbt.base.move(speed*0.9, 0, last_steering)\n",
    "\n",
    "                elif robot_state['signal_detection'] == True:\n",
    "                    if rise_head == 0:\n",
    "                        rbt.base.set_ptz(20)\n",
    "                        time.sleep(3)\n",
    "                        rise_head+=1\n",
    "                    else:\n",
    "                        # 如果有停止标志\n",
    "                        if signal_dict['stop']>5:\n",
    "                            state_info.value = '检测到停止标志'\n",
    "                            speech_word = '检测到停止标志'\n",
    "                            rbt.base.move(0,0,0)\n",
    "                            signal_dict['stop']=0\n",
    "                            rise_head = 0\n",
    "                        else:\n",
    "                            if signal_dict['car_red_yellow']>5:\n",
    "                                state_info.value = '检测到红黄灯'\n",
    "                                speech_word = '检测到红黄灯'\n",
    "                                rbt.base.move(0,0,0)\n",
    "                                signal_dict['car_red_yellow']=0\n",
    "                                rise_head = 0\n",
    "                            elif signal_dict['car_yellow']>5:\n",
    "                                state_info.value = '检测到黄灯'\n",
    "                                speech_word = '检测到黄灯'\n",
    "                                rbt.base.move(0,0,0)\n",
    "                                signal_dict['car_yellow']=0\n",
    "                                rise_head = 0\n",
    "\n",
    "                            elif signal_dict['car_red']>5:\n",
    "                                state_info.value = '检测到红灯'\n",
    "                                speech_word = '检测到红灯'\n",
    "                                rbt.base.move(0,0,0)\n",
    "                                signal_dict['car_red']=0\n",
    "                                rise_head = 0\n",
    "                            else:\n",
    "                                # 如果没有绿灯的情况\n",
    "                                if signal_dict['car_green']==0:\n",
    "                                    state_info.value = '没有检测到绿灯'\n",
    "                                else:\n",
    "                                    state_info.value = '检测到绿灯'\n",
    "\n",
    "                                if signal_dict['forward']>5:\n",
    "                                    state_info.value = '检测到直行'\n",
    "                                    speech_word = '检测到直行'\n",
    "                                    rbt.base.set_ptz(-35)\n",
    "                                    time.sleep(2)\n",
    "                                    rbt.base.forward(0.15, 2, True)\n",
    "                                    signal_dict['forward']=0\n",
    "\n",
    "                                elif signal_dict['left']>5:\n",
    "                                    state_info.value = '检测到左转'\n",
    "                                    speech_word = '检测到左转'\n",
    "                                    rbt.base.set_ptz(-35)\n",
    "                                    time.sleep(2)\n",
    "                                    if signal_dict['aobing']>3 or signal_dict['nezha']>3:\n",
    "                                        rbt.base.move(0,0,0)\n",
    "                                    else:\n",
    "                                        rbt.base.forward(0.15, 2, True)\n",
    "                                        rbt.base.move(0.12,0,0.5,3)\n",
    "                                        signal_dict['left']=0\n",
    "\n",
    "                                elif signal_dict['right']>5:\n",
    "                                    state_info.value = '检测到右转'\n",
    "                                    speech_word = '检测到右转'\n",
    "                                    rbt.base.set_ptz(-35)\n",
    "                                    time.sleep(2)\n",
    "                                    if signal_dict['aobing']>3 or signal_dict['nezha']>3:\n",
    "                                        rbt.base.move(0,0,0)\n",
    "                                    else:\n",
    "                                        rbt.base.forward(0.1, 3, True)\n",
    "                                        rbt.base.move(0.12,0,-0.5,3)\n",
    "                                        signal_dict['right']=0\n",
    "\n",
    "                                elif signal_dict['turn']>5:\n",
    "                                    state_info.value = '检测到掉头'\n",
    "                                    speech_word = '检测到掉头'\n",
    "                                    rbt.base.set_ptz(-35)\n",
    "                                    time.sleep(2)\n",
    "                                    if random.random()<0.5:\n",
    "                                        rbt.base.turnleft(0.55, 6,True)\n",
    "                                    else:\n",
    "                                        rbt.base.turnright(0.55, 6,True)\n",
    "                                    signal_dict['turn']=0\n",
    "                                    \n",
    "                                # 没有其他灯\n",
    "                                else:\n",
    "                                    state_info.value = '没有检测到标识牌'\n",
    "                                    speech_word = '没有检测到标识牌'\n",
    "                                    rbt.base.set_ptz(-35)\n",
    "                                    time.sleep(2)\n",
    "                                    while num_line<5:\n",
    "                                        time.sleep(0.2)\n",
    "                                        rbt.base.move(speed, 0, last_steering)\n",
    "                                        num_line+=1\n",
    "                                robot_state['signal_detection'] = False\n",
    "                                robot_state['road_following'] = True\n",
    "\n",
    "                                signal_dict = init_state\n",
    "                    first_time = time.time()\n",
    "            else:\n",
    "                state_info.value = '前方有障碍'\n",
    "                speech_word = '前方有障碍'\n",
    "                rbt.base.move(0,0,0)\n",
    "# 创建线程\n",
    "process2 = threading.Thread(target=rbt_move,)\n",
    "# 启动线程\n",
    "process2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_speech():\n",
    "    global speech_run\n",
    "    speech_run = True\n",
    "    last_word = ''\n",
    "    while speech_run:\n",
    "        time.sleep(0.05)\n",
    "        global speech_word\n",
    "        current_word = speech_word\n",
    "        if current_word is not None:\n",
    "            if last_word!= current_word:\n",
    "                rbt.speech.play_text(current_word,True)\n",
    "                last_word = current_word\n",
    "# 创建线程\n",
    "process3 = threading.Thread(target=run_speech,)\n",
    "# 启动线程\n",
    "process3.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.连接机器人进行实时检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dd118bf29f4fc8b279746e8881ec91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg'), Image(value=b'', format='jpeg')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f26a978a774efbb280b79882a737c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.0, description='运行速度', max=0.5, step=0.01), FloatSlider(value=1.6, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569b896e95304d7e9ae845f815876461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='当前状态', placeholder='NXROBO')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbt.connect()\n",
    "\n",
    "if rbt_name=='dachbot':\n",
    "    rbt.camera.start(enable_depth_stream=True)\n",
    "    rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_DEPTH,on_new_depth)\n",
    "    rbt.base.set_ptz(-35)\n",
    "    display(widgets.HBox([image_widget, depth_image_widget]))\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, turn_dgain_widget, steering_slider, depth_slider]))\n",
    "    \n",
    "elif rbt_name=='dbot':\n",
    "    rbt.camera.start()\n",
    "    rbt.base.set_ptz(-35)\n",
    "    display(image_widget)\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, turn_dgain_widget, steering_slider]))\n",
    "display(state_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.断开与机器人的连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_flag = False\n",
    "move_robot = False\n",
    "speech_run = False\n",
    "rbt.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbt.base.set_ptz(-35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
