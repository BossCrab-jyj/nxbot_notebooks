{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标跟踪\n",
    "![title](other_data/01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器人目标追踪\n",
    "\n",
    "在这个示例中，我们将展示如何使用机器人进行对象跟踪!我们将使用一个在[COCO 数据集](http://cocodataset.org)上进行预训练的模型来检测90个不同的物体和1个背景类别。\n",
    "包括：人 (索引 0),杯子 (索引 47)...等\n",
    "\n",
    "目标检测区别于我们之前对整个图片的图像识别，而且单一的图像识别他的标签只有一个，比如之前学习的“避障”训练，他的标签就只有“有障碍”或者“无障碍”这样一个类别标签，然而目标检测除了类别标签之外，还有每个类别在图片里的位置和大小信息，而且每张图片还可能有多个类别和位置信息。当我们通过摄像头来检测时目标检测可以识别出图片里它所认识的所有物体并且会用一个矩形框把物体框在里面，在接下来的学习中你可以清楚的看到！你可以在[coco_index.txt](./coco_index.txt)文件中查看所有的类别和对应的索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入我们需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "from nxbot import Robot,event,bgr8_to_jpeg,pid\n",
    "from modules.models import *\n",
    "from modules.utils.util import *\n",
    "from modules.utils.datasets import *\n",
    "import threading\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from traitlets.config.configurable import Configurable\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "from modules.display_box import label_widget\n",
    "from modules.deep_sort import build_tracker\n",
    "from modules.utils.draw import draw_boxes\n",
    "from modules.utils.parser import get_config\n",
    "from modules.utils.log import get_logger\n",
    "from modules.utils.io import write_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_def\", type=str, default=\"modules/config/yolov3-tiny.cfg\", help=\"yolov3-tiny网络结构配置文件\")\n",
    "parser.add_argument(\"--Dachbot_model_path\", type=str, default=\"../../../models/local/yolov3/object_following.weights\", help=\"Dachbot模型文件\")\n",
    "parser.add_argument(\"--Dbot_model_path\", type=str, default=\"../../../models/local/yolov3/object_following.engine\", help=\"Dbot模型文件\")\n",
    "parser.add_argument(\"--deepsort_model_path\", type=str, default=\"modules/config/deep_sort.yaml\", help=\"deepsort配置文件\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"modules/data/coco.names\", help=\"检测类别的所有种类\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.3, help=\"物体置信度\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"非极大抑制阈值\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"网络接收图片大小\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化机器人对象\n",
    "rbt = Robot()\n",
    "# 机器人名字\n",
    "rbt_name = rbt.name\n",
    "\n",
    "cfg = get_config()\n",
    "# 加载跟踪模型配置文件\n",
    "cfg.merge_from_file(opt.deepsort_model_path)\n",
    "\n",
    "# 选择运行模型设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    # 加载跟踪模型\n",
    "    deepsort = build_tracker(cfg, use_cuda=True)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # 加载跟踪模型\n",
    "    deepsort = build_tracker(cfg, use_cuda=False)\n",
    "\n",
    "# 如果是dachbot可以使用更准确的模型\n",
    "if rbt_name=='dachbot':\n",
    "    model = Darknet(opt.model_def, img_size=opt.img_size, TensorRT=False, Half=True).to(device).half()\n",
    "    # 权重加载\n",
    "    model.load_darknet_weights(opt.Dachbot_model_path)\n",
    "    # Set in evaluation mode 前向推理时候会忽略 BatchNormalization 和 Dropout\n",
    "    model.eval()\n",
    "    \n",
    "# 如果是dbot可以使用速度更快的模型    \n",
    "elif rbt_name=='dbot':\n",
    "    model_backbone = Darknet_Backbone(opt.model_def, img_size=opt.img_size).to(device).half()\n",
    "    model = TRTModule()\n",
    "    model.load_state_dict(torch.load(opt.Dbot_model_path))\n",
    "    yolo_head = YOLOHead(config_path=opt.model_def)\n",
    "    \n",
    "# 提取可以识别的类别\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.创建可视化窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg')\n",
    "depth_image_widget = widgets.Image(format='jpeg')\n",
    "speed_widget = widgets.FloatSlider(value=0.2, min=0.0, step=0.01, max=0.5, description='运行速度')\n",
    "turn_gain_widget = widgets.FloatSlider(value=1, min=0.0, step=0.01, max=3.0, description='转向增益')\n",
    "turn_dgain_widget = widgets.FloatSlider(value=0.0, min=0.0, step=0.01, max=2.0, description='回正微调')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='方向')\n",
    "depth_slider = ipywidgets.FloatSlider(min=0.0, max=10000.0, description='深度值')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = np.array(Image.fromarray(image))\n",
    "    imgTensor = transforms.ToTensor()(image)\n",
    "    imgTensor, _ = pad_to_square(imgTensor, 0)\n",
    "    imgTensor = resize(imgTensor, 416)\n",
    "    imgTensor = imgTensor.unsqueeze(0)\n",
    "    imgTensor = Variable(imgTensor.type(Tensor)).half()\n",
    "    return imgTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.检测模型是否能正常运行\n",
    "\n",
    "我们通过numpy创建与我们将要预测的图片格式一致的形状为（416，416，3）的数组，这里我们创建的全为1的数组将这个数组经过预处理再将数据放入模型中，如果能运行通过说明模型可以正常使用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img_data = np.ones([416, 416, 3],np.uint8)\n",
    "    if rbt_name=='dachbot':\n",
    "        model(preprocess(img_data))\n",
    "    elif rbt_name=='dbot':\n",
    "        model(preprocess(img_data))\n",
    "except:\n",
    "    print('请检查模型是否正确')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.打开摄像头深度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global depth\n",
    "depth = 0\n",
    "def on_new_depth(evt):\n",
    "    time.sleep(0.05)\n",
    "    depth_frame = np.asanyarray(evt.dict['data'].get_data())\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_frame, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    depth_colormap = cv2.resize(depth_colormap, (320,240))\n",
    "    depth_image_widget.value = bgr8_to_jpeg(depth_colormap)\n",
    "    \n",
    "    global depth\n",
    "    depth = evt.dict['data'].get_distance(310, 220)\n",
    "    if depth ==0:\n",
    "        depth = evt.dict['data'].get_distance(330, 225)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.定义图像检测\n",
    "在这里我们将通过目标检测模型进行检测，检测出图像中的所有物体，并将所有物体用矩形框将物体框出来，然后在所有物体中找出距离图像中心点最近的物体作为目标物体，如果没有找到目标就停止，如果找到目标机器人就像目标移动，然后根据目标与图像中心点的距离计算出机器人旋转的相对角度，让机器人跟着你走。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择颜色\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype=\"uint8\")\n",
    "\n",
    "global center_x\n",
    "center_x = None\n",
    "global detect_flag\n",
    "detect_flag = True\n",
    "import threading\n",
    "global box_size\n",
    "box_size = 0\n",
    "def prediction():\n",
    "    global detect_flag\n",
    "    results = []\n",
    "    frame_interval = 1\n",
    "    idx_frame = 0\n",
    "    last_steering = 0\n",
    "    \n",
    "    while detect_flag:\n",
    "        global center_x\n",
    "        global box_size\n",
    "        detections = None\n",
    "        origin_img = rbt.camera.read()\n",
    "        if origin_img is not None:\n",
    "            idx_frame += 1\n",
    "            if idx_frame % frame_interval:\n",
    "                continue\n",
    "            image = cv2.cvtColor(origin_img,cv2.COLOR_BGR2RGB)\n",
    "            imgTensor = preprocess(image)\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                detections = model(imgTensor)\n",
    "                if rbt_name=='dbot':\n",
    "                    detections = yolo_head(detections)\n",
    "                # 非极大抑制筛选更加合适的候选框\n",
    "                detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)[0]\n",
    "            \n",
    "            if detections is not None:\n",
    "                # 对预测类别框进行缩放\n",
    "                bbox_xywh=[]\n",
    "                cls_conf_list = []\n",
    "                detections = rescale_boxes(detections, opt.img_size, origin_img.shape[:2])\n",
    "\n",
    "                 # 目标跟踪类别名称\n",
    "                choose_label = label_widget.children[0].children[1].value.strip()\n",
    "                # 在图像上框出对应类别\n",
    "                # 筛选出我们想要检测的对象\n",
    "                for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                    if choose_label == classes[int(cls_pred)]:\n",
    "                        box_w = x2 - x1\n",
    "                        box_h = y2 - y1\n",
    "                        center_x = box_w/2+x1\n",
    "                        center_y = box_h/2+y1\n",
    "                        bbox_xywh.append([center_x, center_y, box_w, box_h])\n",
    "                        cls_conf_list.append(cls_conf)\n",
    "                \n",
    "                bbox_xywh = np.asarray(bbox_xywh)\n",
    "                cls_conf_list = np.asarray(cls_conf_list)\n",
    "                if len(bbox_xywh)>0:\n",
    "                    outputs = deepsort.update(bbox_xywh, cls_conf_list, image)\n",
    "                    if len(outputs) > 0:\n",
    "                        bbox_tlwh = []\n",
    "                        bbox_xyxy = outputs[:, :4]\n",
    "                        identities = outputs[:, -1]\n",
    "                        ori_im = draw_boxes(origin_img, bbox_xyxy, identities)\n",
    "                        for bb_xyxy in bbox_xyxy:\n",
    "                            bbox_tlwh.append(deepsort._xyxy_to_tlwh(bb_xyxy))\n",
    "                        results.append((idx_frame - 1, bbox_tlwh, identities))\n",
    "                        center_x = (bbox_xyxy[0][2]-bbox_xyxy[0][0])/2+bbox_xyxy[0][0]\n",
    "                        speed = speed_widget.value\n",
    "                        steering = (0.5-center_x/300)*turn_gain_widget.value\n",
    "                        steering = steering - (steering + last_steering)*turn_dgain_widget.value\n",
    "                        steering_slider.value = steering\n",
    "                        last_steering = steering\n",
    "                        # 机器人腊肠狗控制\n",
    "                        if rbt_name=='dachbot':\n",
    "                            if depth < 1.0 and depth!=0:\n",
    "                                rbt.base.move(-speed, 0, 0)\n",
    "                            elif depth>1.2 and depth!=0:\n",
    "                                rbt.base.move(speed, 0, steering)\n",
    "                            else:\n",
    "                                rbt.base.move(0,0,0)\n",
    "                        # 机器人天秤座控制\n",
    "                        elif rbt_name=='dbot':\n",
    "                            if box_size > 0.5:\n",
    "                                rbt.base.move(-speed, 0, 0)\n",
    "                            elif box_size < 0.4:\n",
    "                                rbt.base.move(speed, 0, steering)\n",
    "                            else:\n",
    "                                rbt.base.move(0,0,0)\n",
    "                    else:\n",
    "                        rbt.base.move(0,0,0)\n",
    "                else:\n",
    "                    rbt.base.move(0,0,0)    \n",
    "            else:\n",
    "                rbt.base.move(0,0,0)            \n",
    "            origin_img = cv2.resize(origin_img, (320, 240), interpolation=cv2.INTER_CUBIC)\n",
    "            image_widget.value=bgr8_to_jpeg(origin_img)\n",
    "        else:\n",
    "            rbt.base.move(0,0,0)\n",
    "# 创建线程\n",
    "process1 = threading.Thread(target=prediction,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.创建机器人运动线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建机器人运动线程\n",
    "def action():\n",
    "    global detect_flag\n",
    "    global center_x\n",
    "    global box_size\n",
    "    global depth\n",
    "    depth_slider.value = depth\n",
    "    last_steering = 0\n",
    "    steering = None\n",
    "    \n",
    "    # PID参数\n",
    "    xservo_pid = pid.PositionalPID(1.5, 0.002, 3)\n",
    "    \n",
    "    while detect_flag:\n",
    "        time.sleep(0.05)\n",
    "        speed = speed_widget.value\n",
    "        if center_x is not None:\n",
    "            steering0 = center_x/300*turn_gain_widget.value\n",
    "            xservo_pid.SystemOutput = steering0\n",
    "            xservo_pid.SetStepSignal(0.5)\n",
    "            xservo_pid.SetInertiaTime(0.1, 0.06)\n",
    "            steering = xservo_pid.SystemOutput\n",
    "            steering_slider.value = steering\n",
    "        # 机器人腊肠狗控制\n",
    "        if rbt_name=='dachbot':\n",
    "            if depth < 1.0 and depth!=0:\n",
    "                rbt.base.move(-speed, 0, 0)\n",
    "            elif depth>1.2 and depth!=0:\n",
    "                if steering is not None:\n",
    "                    rbt.base.move(speed, 0, steering)\n",
    "                else:\n",
    "                    rbt.base.move(0,0,0)\n",
    "            else:\n",
    "                rbt.base.move(0,0,0)\n",
    "        # 机器人天秤座控制\n",
    "        elif rbt_name=='dbot':\n",
    "            if center_x is not None:\n",
    "                if box_size > 0.5:\n",
    "                    rbt.base.move(-speed, 0, 0)\n",
    "                elif box_size < 0.4:\n",
    "                    if steering is not None:\n",
    "                        rbt.base.move(speed, 0, steering)\n",
    "                    else:\n",
    "                        rbt.base.move(0,0,0)\n",
    "                else:\n",
    "                    rbt.base.move(0,0,0)\n",
    "            else:\n",
    "                rbt.base.move(0,0,0)\n",
    "        \n",
    "        center_x = None\n",
    "        steering = None\n",
    "        \n",
    "# 创建线程\n",
    "process2 = threading.Thread(target=action,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.连接机器人进行实时检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.connect()\n",
    "\n",
    "if rbt_name=='dachbot':\n",
    "    rbt.camera.start(enable_depth_stream=True)\n",
    "    rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_DEPTH,on_new_depth)\n",
    "    rbt.base.set_ptz(20)\n",
    "    display(widgets.HBox([image_widget, depth_image_widget]))\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, label_widget]))\n",
    "    display(steering_slider, depth_slider)\n",
    "elif rbt_name=='dbot':\n",
    "    rbt.camera.start()\n",
    "    rbt.base.set_ptz(20)\n",
    "    display(image_widget)\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, turn_dgain_widget, steering_slider]))\n",
    "    display(label_widget)\n",
    "\n",
    "process1.start()\n",
    "process2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.断开与机器人的连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_flag = False\n",
    "# rbt.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
