{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标跟踪\n",
    "![title](other_data/01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器人目标追踪\n",
    "\n",
    "在这个示例中，我们将展示如何使用机器人进行对象跟踪!我们将使用一个在[COCO 数据集](http://cocodataset.org)上进行预训练的模型来检测90个不同的物体和1个背景类别。\n",
    "包括：人 (索引 0),杯子 (索引 47)...等\n",
    "\n",
    "目标检测区别于我们之前对整个图片的图像识别，而且单一的图像识别他的标签只有一个，比如之前学习的“避障”训练，他的标签就只有“有障碍”或者“无障碍”这样一个类别标签，然而目标检测除了类别标签之外，还有每个类别在图片里的位置和大小信息，而且每张图片还可能有多个类别和位置信息。当我们通过摄像头来检测时目标检测可以识别出图片里它所认识的所有物体并且会用一个矩形框把物体框在里面，在接下来的学习中你可以清楚的看到！你可以在[coco_index.txt](./coco_index.txt)文件中查看所有的类别和对应的索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入我们需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "from nxbot import Robot,event,bgr8_to_jpeg\n",
    "from modules.models import *\n",
    "from modules.utils.util import *\n",
    "from modules.utils.datasets import *\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from traitlets.config.configurable import Configurable\n",
    "from torch2trt import TRTModule\n",
    "from modules.display_box import label_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_def\", type=str, default=\"modules/config/yolov3-tiny.cfg\", help=\"yolov3-tiny网络结构配置文件\")\n",
    "parser.add_argument(\"--Dachbot_model_path\", type=str, default=\"../../models/object_detection_model/yolov3-tiny.weights\", help=\"Dachbot模型文件\")\n",
    "parser.add_argument(\"--Dbot_model_path\", type=str, default=\"../../models/object_detection_model/yolo_v3_tiny.engine\", help=\"Dbot模型文件\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"modules/data/coco.names\", help=\"检测类别的所有种类\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.3, help=\"物体置信度\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"非极大抑制阈值\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"网络接收图片大小\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化机器人对象\n",
    "rbt = Robot()\n",
    "# 机器人名字\n",
    "rbt_name = rbt.name\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 如果是dachbot可以使用更准确的模型\n",
    "if rbt_name=='dachbot':\n",
    "    model = Darknet(opt.model_def, img_size=opt.img_size, TensorRT=False, Half=True).to(device).half()\n",
    "    # 权重加载\n",
    "    model.load_darknet_weights(opt.Dachbot_model_path)\n",
    "    # Set in evaluation mode 前向推理时候会忽略 BatchNormalization 和 Dropout\n",
    "    model.eval()\n",
    "    \n",
    "# 如果是dbot可以使用速度更快的模型    \n",
    "elif rbt_name=='dbot':\n",
    "    model_backbone = Darknet_Backbone(opt.model_def, img_size=opt.img_size).to(device).half()\n",
    "    model = TRTModule()\n",
    "    model.load_state_dict(torch.load(opt.Dbot_model_path))\n",
    "    yolo_head = YOLOHead(config_path=opt.model_def)\n",
    "    \n",
    "# 提取可以识别的类别\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.创建可视化窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg')\n",
    "depth_image_widget = widgets.Image(format='jpeg')\n",
    "speed_widget = widgets.FloatSlider(value=0.0, min=0.0, step=0.01, max=0.5, description='运行速度')\n",
    "turn_gain_widget = widgets.FloatSlider(value=0.15, min=0.0, step=0.01, max=1.0, description='转向增益')\n",
    "turn_dgain_widget = widgets.FloatSlider(value=0.03, min=0.0, step=0.01, max=5.0, description='回正微调')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='方向')\n",
    "depth_slider = ipywidgets.FloatSlider(min=0.0, max=10000.0, description='深度值')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.定义目标检测\n",
    "在这里我们将让机器人识别出它所看到的所有物体，并且判断距离图像中心点最近的物体是否与我们设定的目标物体一致（我们默认的是索引1，代表跟踪的目标是人），如果是设定目标，就跟着目标走，并根据物体再图像的位置让机器人判断左转还是右转。\n",
    "\n",
    "### 5.1.计算识别的物体的中心点坐标相对于图片中心点的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_center(detection):\n",
    "    bbox = detection\n",
    "    dis_x = 0.5-((bbox[2] - bbox[0])/2+bbox[0])\n",
    "    dis_y = 0.5-((bbox[3] - bbox[1])/2+bbox[1])\n",
    "    return (dis_x, dis_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.计算图片中心点与物体的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(vec):\n",
    "    return np.sqrt(np.float(vec[0])**2 + np.float(vec[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.在检测到的物体中找出与中心点最近的那一个物体作为目标物体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_detection(matching_labels):\n",
    "    closest_det = None\n",
    "    for det in matching_labels:\n",
    "        if closest_det is None:\n",
    "            closest_det = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_det)):\n",
    "            closest_det = det\n",
    "    return closest_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = np.array(Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)))\n",
    "    imgTensor = transforms.ToTensor()(image)\n",
    "    imgTensor, _ = pad_to_square(imgTensor, 0)\n",
    "    imgTensor = resize(imgTensor, 416)\n",
    "    imgTensor = imgTensor.unsqueeze(0)\n",
    "    imgTensor = Variable(imgTensor.type(Tensor)).half()\n",
    "    return imgTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.检测模型是否能正常运行\n",
    "\n",
    "我们通过numpy创建与我们将要预测的图片格式一致的形状为（416，416，3）的数组，这里我们创建的全为1的数组将这个数组经过预处理再将数据放入模型中，如果能运行通过说明模型可以正常使用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img_data = np.ones([416, 416, 3],np.uint8)\n",
    "    if rbt_name=='dachbot':\n",
    "        model(preprocess(img_data)).detach().half().cpu().numpy().flatten()\n",
    "    elif rbt_name=='dbot':\n",
    "        model(preprocess(img_data))\n",
    "except:\n",
    "    print('请检查模型是否正确')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.打开摄像头深度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global depth\n",
    "depth = 0\n",
    "def on_new_depth(evt):\n",
    "    depth_frame = np.asanyarray(evt.dict['data'].get_data())\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_frame, alpha=0.03), cv2.COLORMAP_JET)\n",
    "    depth_colormap = cv2.resize(depth_colormap, (320,240))\n",
    "    depth_image_widget.value = bgr8_to_jpeg(depth_colormap)\n",
    "    \n",
    "    global depth\n",
    "    depth = evt.dict['data'].get_distance(310, 220)\n",
    "    if depth ==0:\n",
    "        depth = evt.dict['data'].get_distance(330, 225)\n",
    "    depth_slider.value = depth\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.定义图像检测\n",
    "在这里我们将通过目标检测模型进行检测，检测出图像中的所有物体，并将所有物体用矩形框将物体框出来，然后在所有物体中找出距离图像中心点最近的物体作为目标物体，如果没有找到目标就停止，如果找到目标机器人就像目标移动，然后根据目标与图像中心点的距离计算出机器人旋转的相对角度，让机器人跟着你走。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化列表，用于存放识别结果\n",
    "all_pred=[]\n",
    "# 随机选择颜色\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype=\"uint8\")\n",
    "\n",
    "last_steering = 0\n",
    "\n",
    "def on_new_image(evt):\n",
    "    \n",
    "    global last_steering\n",
    "    origin_img = evt.dict['data']\n",
    "    # 对图像数据进行预处理\n",
    "    imgTensor = preprocess(origin_img)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 将图像数据放入模型进行预测\n",
    "        detections = model(imgTensor)\n",
    "        # 如果是dbot采用另外一种方法\n",
    "        if rbt_name=='dbot':\n",
    "            detections = yolo_head(detections)\n",
    "        # 非极大抑制筛选更加合适的候选框\n",
    "        detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)\n",
    "\n",
    "    all_pred.clear()\n",
    "    # 如果检测到类别就将结果放在all_pred列表中\n",
    "    if detections is not None: \n",
    "        all_pred.extend(detections)\n",
    "\n",
    "    b=len(all_pred)\n",
    "    if len(all_pred):\n",
    "        # 将所有识别结果在图像中标注出来\n",
    "        for detections in all_pred:\n",
    "            if detections is not None:\n",
    "                # 对预测类别框进行缩放\n",
    "                detections = rescale_boxes(detections, opt.img_size, origin_img.shape[:2])\n",
    "                # 在图像上框出对应类别\n",
    "                for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                    box_w = x2 - x1\n",
    "                    box_h = y2 - y1\n",
    "                    color = [int(c) for c in colors[int(cls_pred)]]\n",
    "                    img = cv2.rectangle(origin_img, (x1, y1 + box_h), (x2, y1), color, 2)\n",
    "                    cv2.putText(origin_img, classes[int(cls_pred)], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                    cv2.putText(origin_img, str(\"%.2f\" % float(conf)), (x2, y2 - box_h), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                color, 2)\n",
    "                \n",
    "                # 目标跟踪类别名称\n",
    "                choose_label = label_widget.children[0].children[1].value.strip()\n",
    "                # 如果图中有与我们选择的类别一致，就将所有该类别信息放入列表matching_labels中\n",
    "                matching_labels = [d for d in detections if classes[int(d[6])] == choose_label]\n",
    "                \n",
    "                # 如果没有找到想要跟踪的类别就停下来\n",
    "                if matching_labels == []:\n",
    "                    rbt.base.move(0, 0, 0)\n",
    "                    \n",
    "                # 如果有就计算类别与图像中心点的距离再根据距离自动进行回正\n",
    "                else:\n",
    "                    # 距离图片中心最近的跟踪类别\n",
    "                    matching_label = closest_detection(matching_labels)/origin_img.shape[1]\n",
    "                    # 计算该类别到图中心的距离\n",
    "                    distance_x = detection_center(matching_label)[0]\n",
    "                   \n",
    "                    # 根据距离计算转向值\n",
    "                    steering = distance_x*turn_gain_widget.value\n",
    "                    steering = steering - (steering + last_steering)*turn_dgain_widget.value\n",
    "                    speed = speed_widget.value\n",
    "                    steering_slider.value = steering\n",
    "                    \n",
    "                     # 如果是dachbot就使用深度摄像头的深度信息\n",
    "                    if rbt_name=='dachbot':\n",
    "                        global depth\n",
    "                        distance_z = depth\n",
    "                        # 根据距离判断机器人前进还是后退还是停下来\n",
    "                        if distance_z > 0.5 and distance_z!=0:\n",
    "                            rbt.base.move(speed, 0, steering)\n",
    "\n",
    "                        elif distance_z < 0.4 and distance_z!=0:\n",
    "                            rbt.base.move(-speed, 0, steering)\n",
    "                        else:\n",
    "                            rbt.base.move(0,0,0)\n",
    "                            \n",
    "                    # 如果是dbot就根据类别框的大小计算判断机器人与物体距离的远近\n",
    "                    elif rbt_name=='dbot':\n",
    "                        box_size = (matching_label[2]-matching_label[0])*(matching_label[3]-matching_label[1])\n",
    "                        # 根据距离判断机器人前进还是后退还是停下来\n",
    "                        if box_size > 0.5:\n",
    "                            rbt.base.move(-speed, 0, steering)\n",
    "                        elif box_size < 0.4:\n",
    "                            rbt.base.move(speed, 0, steering)\n",
    "                        else:\n",
    "                            rbt.base.move(0,0,0)\n",
    "                    last_steering = steering\n",
    "            else:\n",
    "                rbt.base.move(0,0,0)\n",
    "    else:\n",
    "        rbt.base.move(0,0,0)\n",
    "        \n",
    "    origin_img = cv2.resize(origin_img, (320, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    image_widget.value=bgr8_to_jpeg(origin_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.连接机器人进行实时检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbt.connect()\n",
    "\n",
    "if rbt_name=='dachbot':\n",
    "    rbt.camera.start(enable_depth_stream=True)\n",
    "    rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_IMAGE,on_new_image)\n",
    "    rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_DEPTH,on_new_depth)\n",
    "    rbt.base.set_ptz(20)\n",
    "    display(widgets.HBox([image_widget, depth_image_widget]))\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, label_widget]))\n",
    "    display(steering_slider, depth_slider)\n",
    "elif rbt_name=='dbot':\n",
    "    rbt.camera.start()\n",
    "    rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_IMAGE,on_new_image)\n",
    "    rbt.base.set_ptz(20)\n",
    "    display(image_widget)\n",
    "    display(widgets.VBox([speed_widget,turn_gain_widget, turn_dgain_widget, steering_slider]))\n",
    "    display(label_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.断开与机器人的连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbt.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
