{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************\n",
      "*                NXROBO - Dachbot机器人                *\n",
      "*       (c) 2019 J.Xiao <jie.xiao@nxrobo.com>          *\n",
      "*                https://www.nxrobo.com                *\n",
      "********************************************************\n",
      "               当前SDK版本: 0.3.2.dev\n",
      "            如需退出，可以按 Ctrl-C 组合键\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from nxbot import Robot,event,bgr8_to_jpeg\n",
    "import traitlets\n",
    "from traitlets.config.configurable import Configurable\n",
    "import ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(class_path='data/coco.names', conf_thres=0.2, img_size=416, model_def='config/yolov3-tiny.cfg', nms_thres=0.4, weights_path='weights/yolov3-tiny.weights')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_def\", type=str, default=\"config/yolov3-tiny.cfg\", help=\"yolov3-tiny网络结构配置文件\")\n",
    "parser.add_argument(\"--weights_path\", type=str, default=\"weights/yolov3-tiny.weights\", help=\"模型文件\")\n",
    "parser.add_argument(\"--class_path\", type=str, default=\"data/coco.names\", help=\"检测类别的所有种类\")\n",
    "parser.add_argument(\"--conf_thres\", type=float, default=0.2, help=\"物体置信度\")\n",
    "parser.add_argument(\"--nms_thres\", type=float, default=0.4, help=\"非极大抑制阈值\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=416, help=\"网络接收图片大小\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Half = True    # 半精度\n",
    "\n",
    "if Half:\n",
    "    model = Darknet(opt.model_def, img_size=opt.img_size, TensorRT=False, Half=True).to(device).half()\n",
    "else:\n",
    "    model = Darknet(opt.model_def, img_size=opt.img_size).to(device)\n",
    "\n",
    "# 权重加载\n",
    "if opt.weights_path.endswith(\".weights\"):\n",
    "    # Load darknet weights\n",
    "    model.load_darknet_weights(opt.weights_path)\n",
    "else:\n",
    "    # Load checkpoint weights\n",
    "    model.load_state_dict(torch.load(opt.weights_path))\n",
    "# Set in evaluation mode 前向推理时候会忽略 BatchNormalization 和 Dropout\n",
    "model.eval()\n",
    "\n",
    "\n",
    "classes = load_classes(opt.class_path)  # Extracts class labels from file\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "imgs = []  # Stores image paths\n",
    "img_detections = []  # Stores detections for each image index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image,Half):\n",
    "    image = np.array(Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB)))\n",
    "#     print(image.size)\n",
    "    imgTensor = transforms.ToTensor()(image)\n",
    "    imgTensor, _ = pad_to_square(imgTensor, 0)\n",
    "    imgTensor = resize(imgTensor, 416)\n",
    "    imgTensor = imgTensor.unsqueeze(0)\n",
    "    if Half:\n",
    "        imgTensor = Variable(imgTensor.type(Tensor)).half()\n",
    "    else:\n",
    "        imgTensor = Variable(imgTensor.type(Tensor))\n",
    "    return imgTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.155e+01 1.788e+01 7.981e+01 ... 1.367e-03 9.623e-04 2.306e-03]\n",
      "2.982889413833618\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "img_data = np.ones([224, 224, 3],np.uint8)\n",
    "xy = model(preprocess(img_data, Half)).detach().half().cpu().numpy().flatten()\n",
    "end = time.time()-start\n",
    "print(xy)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred=[]\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype=\"uint8\")\n",
    "\n",
    "def on_new_image(evt):\n",
    "    origin_img = evt.dict['data']\n",
    "    imgTensor = preprocess(origin_img, Half)\n",
    "    with torch.no_grad():\n",
    "        detections = model(imgTensor)\n",
    "        detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)\n",
    "\n",
    "    all_pred.clear()\n",
    "    if detections is not None:\n",
    "        all_pred.extend(detections)\n",
    "\n",
    "    b=len(all_pred)\n",
    "    if len(all_pred):\n",
    "\n",
    "        for detections in all_pred:\n",
    "            if detections is not None:\n",
    "                detections = rescale_boxes(detections, opt.img_size, origin_img.shape[:2])\n",
    "                for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "                    box_w = x2 - x1\n",
    "                    box_h = y2 - y1\n",
    "                    color = [int(c) for c in colors[int(cls_pred)]]\n",
    "                    #print(cls_conf)\n",
    "                    img = cv2.rectangle(origin_img, (x1, y1 + box_h), (x2, y1), color, 2)\n",
    "                    cv2.putText(origin_img, classes[int(cls_pred)], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 3)\n",
    "                    cv2.putText(origin_img, str(\"%.2f\" % float(conf)), (x2, y2 - box_h), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                                color, 2)\n",
    "                    \n",
    "    origin_img = cv2.resize(origin_img, (320, 240), interpolation=cv2.INTER_CUBIC)\n",
    "    image_widget.value=bgr8_to_jpeg(origin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff3f157044f4d35b300785366ff3861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbt = Robot()\n",
    "rbt.connect()\n",
    "rbt.base.set_ptz(20)\n",
    "rbt.camera.start()\n",
    "rbt.event_manager.add_event_listener(event.EventTypes.NEW_CAMERA_IMAGE,on_new_image)\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbt.base.set_ptz(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbt.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
