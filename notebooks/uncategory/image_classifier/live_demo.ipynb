{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络-CNN\n",
    "\n",
    "* 图像识别\n",
    "\n",
    "## 什么是图像识别？\n",
    "* 图像识别技术是人工智能的一个重要领域。它是指计算机通过对图像进行分析，使计算机在不同场景下识别出图像里面的内容。\n",
    "* 计算机本身不具有理解图像的能力，图像识别就是让计算机有和人类一样对图像理解的能力，包括图像表示的内容，图像中物体之间的关系等要素。\n",
    "\n",
    "![title](other/detect.jpg)\n",
    "\n",
    "## 图像识别技术原理\n",
    "\n",
    "计算机的图像识别技术和人类的图像识别在原理上并没有本质的区别，人类的图像识别都是依靠图像所具有的本身特征分类，然后通过各个类别所具有的特征将图像识别出来的，我们的大脑会根据存储记忆中已经分好的类别进行识别，查看是否有与该图像具有相同或类似特征的存储记忆，从而识别出是否见过该图像。\n",
    "因此我们会让机器以相同的模式来学习和分析，让机器具有图像识别的能力。\n",
    "\n",
    "## 机器如何学习？\n",
    "说起图像识别就不得不提到神经网络了\n",
    "\n",
    "![title](other/1.webp)\n",
    "\n",
    "机器通过神经网络学习到物体的轮廓，颜色，纹理等特征，并通过计算将这些特征记录下来，就可以得到一个分类模型了，最终我们既可以通过这个模型进行图像识别了。\n",
    "\n",
    "![title](other/detail.jpg)\n",
    "\n",
    "## 那么图像识别具体是怎样操作的呢？\n",
    "* 主要包括以下步骤：\n",
    "1. 确定需要机器识别的物体种类，收集该物体的图像，并将收集的图片标记对应的标签；\n",
    "2. 对收集的图像进行预处理；\n",
    "3. 构建神经网络；\n",
    "4. 加载图像，将图像输入神经网络进行训练并保存模型；\n",
    "5. 对模型进行评估。\n",
    "\n",
    "在接下来的这个实验中我们将学习到如何通过神经网络训练出能识别小狗的模型。\n",
    "\n",
    "* 首先导入我们需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*- \n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小狗数据集\n",
    "\n",
    "在这里我们已经提供了小狗的数据集，文件路径在“dataset”目录下，里面有4个子目录，包括“train_max”,“train_min”, “val”,\"test\"。\n",
    "1. “train_max”包含有两个文件夹，文件夹“dog”包含有500张小狗图片，“none”包含500张没有小狗的图片；\n",
    "2. “train_min”包含有两个文件夹，文件夹“dog”包含有200张小狗图片，“none”包含200张没有小狗的图片，在接下来的实验中我们会分别用“train_max”,“train_min”两个数据集对神经网络进行训练，区分不同数据集对模型准确率的影响；\n",
    "3.  “val”包含有两个文件夹，文件夹“dog”包含有50张小狗图片，“none”包含50张没有小狗的图片，用于在训练时对模型进行评估，我们将准确率最高的模型保存下来；\n",
    "4.  最终通过“test”文件夹里面数据集对模型进行测试。\n",
    "\n",
    "> 首先使用“train_min”小批量的数据集来进行训练，然后设置我们的数据集的类别，这里我们可以通过python规则class_names[0], class_names[1]分别将'有狗'和 '没有狗'提取出来，在接下来的学习中会用到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_dir = '../../../models/local/datasets/cnn_teach/train_min'\n",
    "class_names = ['有狗', '没有狗']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "首先我们需要了解的是图片的格式，对于机器来说他只能把图片信息转化为数字信息他才能看懂，每一张图片都是由很多个像素组成的，每个像素是通过RGB（红绿蓝）3个通道的数值来存储的，数值范围在（0，255），当RGB分别的数值不同时就可以构造出千变万化的颜色了，然后再根据设置长宽就可以构造出图片了。\n",
    "\n",
    "![title](other/RGB.jpg)\n",
    "\n",
    "* 数据预处理主要包括有：\n",
    "1. transforms.ColorJitter() 功能：调整亮度、对比度、饱和度和色相\n",
    "\n",
    "![title](other/color.jpg)\n",
    "\n",
    "2. transforms.Resize((224, 224))，在这个实验中我们将会用到“alexnet”神经网络，这个神经网络接收的图片像素为224×224，因此我们将改变所有输入神经网络的图片像素大小。\n",
    "3. transforms.ToTensor()，将图片数据格式转换我们使用的“pytorch”深度学习框架所能理解的数据格式，因此我们将图片数据转换为“tensor”格式,并且将数据归一化至[0-1] \n",
    "4. transforms.Normalize()， 使图像数据的分布范围限定在[-1,1]之间，在这样的分布情况下，我们神经网络就可以更好的学习到图片的特征。\n",
    "\n",
    "![title](other/hince.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosees(raw_data):\n",
    "    pre_datasets = datasets.ImageFolder(raw_data,transforms.Compose([\n",
    "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))\n",
    "    return pre_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置数据加载器\n",
    "我们会通过“torch”框架提供的“utils.data.DataLoader()”函数将数据添加在加载器里，只要将我们的数据按照以下方式进行保存就可以很方便的读取数据了。\n",
    "* 数据集文件夹格式必须为：\n",
    "> train_max/dog/\n",
    "        dog/*img_001.jpg*\n",
    "        dog/*img_002.jpg*\n",
    "        ...\n",
    "    train_max/none/\n",
    "        none/*img_001.jpg*\n",
    "        none/*img_002.jpg*\n",
    "        ....\n",
    "1. batch_size：加载器每次输出给神经网络的图片数量为16张；\n",
    "2. shuffle：是否打乱图片顺序，一般会将训练的数据集进行顺序打乱，使数据有更高的随机性，提高模型性能；\n",
    "3. num_workers：使用电脑cpu的核心数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(pre_datasets, shuffle):\n",
    "    data = torch.utils.data.DataLoader(\n",
    "            pre_datasets,\n",
    "            batch_size=16,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=4\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练数据集到数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_min = preprosees(min_train_dir)\n",
    "min_train_loader = dataloader(pre_train_min, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示部分数据\n",
    "我们可以通过“matplotlib”模块将图片显示出来，因为之前设置的batch_size=16，这里只显示1个batch_size的图片。你也可以通过打开对应的文件夹进行查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):    \n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# 读取图片和图片标签\n",
    "inputs, classes = next(iter(min_train_loader))\n",
    "# 图片拼接\n",
    "out = torchvision.utils.make_grid(inputs, nrow=4)\n",
    "print('训练的图片分别为：', [class_names[x] for x in classes])\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义卷积神经网络CNN\n",
    "\n",
    "什么是神经网络？\n",
    "* 在简单的线性二分类中我们只需要找到 f(x) = wx+b 这么一条线满足所有点到直线的距离最小时就可以将数据分类了.\n",
    "\n",
    "![title](other/linear.jpg)\n",
    "* 但是在下图当线性不可分时，f(x) = wx+b这个函数就无法表达出分类的效果了，因为这个函数是一条直线，没有办法进行非线性分类。\n",
    "\n",
    "![title](other/not_linear.jpg)\n",
    "\n",
    "* 因此神经网络就是通过很多个线性函数和非线性函数的组合这样就可以表达出各种各样的分类情况了。在神经网络中每一个“神经元（下图中的连接点就代表“神经元”）”就代表一个函数，我们将“w”称为权重，“b”称为偏置，一般模型的好坏就取决于“w”权重的值是否合理。\n",
    "\n",
    "![title](other/network.jpg)\n",
    "\n",
    "* Alexnet：\n",
    "\n",
    "![title](other/2.jpg)\n",
    "\n",
    "* 我们以Alexnet为例，该网络有1个输入层，8个隐藏层和1个输出层,隐藏层包含有5层卷积和3层全连接。\n",
    "\n",
    "其中在网络中有3个常用的模块。\n",
    "\n",
    "> 1. “Conv2d”表示卷积操作用来提取图像特征，“conv2d”有三个基本参数包括：（kernel_size = 卷积核大小（下图的3×3阴影部分方块表示卷积核，上面3×3的方块表示通过卷积核卷积过后提取到的特征图我们称之为“feature map”），stride = 步长（如下图步长为2，可以看到卷积核每次移动的方块为2格）， pading = 下图（白色方块区域pading=1，当图片不能被卷积核完整扫描时需要设置pading）如下图所示；\n",
    "\n",
    "![title](other/conv_pading.gif)\n",
    "\n",
    "> 2. “relu”非线性激活函数提高模型表达能力；\n",
    "\n",
    "![title](other/relu.png)\n",
    "\n",
    "> 3. “MaxPool2d”最大池化层用于在卷积操作时，特征提取的过程中产生的冗余信息\n",
    "\n",
    "![title](other/Maxpooling2d.png)\n",
    "\n",
    "* 设置网络具体步骤：\n",
    "\n",
    "    1. 首先我们将大小为batch_size张224×224×3的图片输入神经网络，我们用[batch_size, 224, 224, 3]4维数组表示；\n",
    "    2. 然后通过5次卷积将图片变成了数组为[batch_size, 5, 5, 256]的特征图（feature map）；\n",
    "    3. 然后我们通过降维，将 [batch_size, 5, 5, 256] 4维数组转换为[batch_size, 6400]2维数组；\n",
    "    4. 然后通过3层全连接将数组重组得到新的[batch_size, 6400]2维数组。\n",
    "    5. 最后将数组[batch_size, 6400]降为[batch_size, 2],因为我们想预测2个类别，所以这里的[batch_size, 2]表示我们所输入有batch_size张图片，每张图片有2个通过神经网络输出的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self,num_class=2):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            #卷积层1\n",
    "            nn.Conv2d(3,96,kernel_size=11,stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            #卷积层2\n",
    "            nn.Conv2d(96,256,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    " \n",
    "            #卷积层3\n",
    "            nn.Conv2d(256,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    " \n",
    "            #卷积层4\n",
    "            nn.Conv2d(384,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    " \n",
    "            #卷积层5\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)   \n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            #全连接层6\n",
    "            nn.Linear(256 * 5 * 5, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    " \n",
    "            #全连接层7\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    " \n",
    "            #全连接层8\n",
    "            nn.Linear(4096,num_class)\n",
    "            \n",
    "        )\n",
    "    # 前向传播，包括输入层，隐藏层和输出层。\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载神经网络\n",
    "上面我们定义了alexnet，接下来我们需要将它实例化，通过“alex_model”表示，如果我们有显卡的话就可以使用GPU对模型计算进行加速，如果没有就使用cpu进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alex_model = AlexNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alex_model = alex_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型训练\n",
    "模型到底是如何训练的？\n",
    "1. 激活函数sigmoid：\n",
    "* 在上面我们已经定义好了alexnet网络了，那么如何通过网络来对模型进行训练呢？在定义alexnet时我们直到，网络最后输出的是[batch_size, 2]这么一个数组，表示每张图片有2个通过神经网络输出的值。这个值有什么意义呢？我们怎么通过这两个值来判断这张图片到底是个什么类别呢？\n",
    "* 因此接下来就学习这个神奇的激活函数sigmoid，可以看到当x<0时，y[0, 0.5];当x>0时，y[0.5, 1]，sigmoid函数S(x)的取值区间在[0, 1]这对于我们分类来说是一个很好的性质，当我们将通过神经网络输出来的2个向量，再通过sigmoid函数计算就可以得到2个新的处于[0, 1]区间的向量，这不正好表达了两个类别分别的概率吗？ \n",
    "\n",
    "![title](other/sigmoid.gif)\n",
    "\n",
    "2. 损失函数：\n",
    "\n",
    ">“onehot”定义标签\n",
    "\n",
    "* 现在我们通过神经网络已经预测出这两个类别分别的概率了，虽然这个概率不一定准确，我们的目的就是想让这个概率更加准确，然而我们定义的标签是用['有狗', '没有狗']来表示的，一个是数字一个是文字没有办法进行比较啊，因此我们想到了一个很好的办法，“onehot”编码，我们定义，在训练数据集中如果这张图片是“有狗”的图片，那么我么就把这个图片的标签用[1, 0]表示，反之就用[0, 1]来表示。如果我们有3个类别，分别为：猫，狗，猪，那我们就可以用[1,0,0]来表示猫，[0,1,0]来表示狗，[0,0,1]来表示猪，需要注意的是，要记住排列的顺序。\n",
    "\n",
    "> 计算损失值“Loss”\n",
    "\n",
    "* 分类损失函数“cross_entropy”\n",
    "* 交叉熵是用来评估当前训练得到的概率分布与真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。其中 p(x) 是指真实分布的概率， q(x) 是模型通过数据计算出来的概率估计。因此我们就可以通过由onehot标记的真实标签和通过神经网络计算出的预测值就可以计算出两者之间的误差，也叫做损失值Loss。\n",
    "\n",
    "![title](other/cross_entropy.jpg)\n",
    "\n",
    "3. 梯度下降更新模型:\n",
    "\n",
    "![title](other/gradient.svg)\n",
    "\n",
    "\n",
    "* 神经网络经过一个epoch计算后，就会得到一个模型，但是这个模型并不准确，那我们应该怎样使模型更加准确呢？我们之前讲过，模型的好坏是和权重相关的，因此只有改变权重，我们的Loss值才会有变化。当Loss足够小时，说明我们的模型就被训练得很好了，因此这就是一个关于权重“w”求Loss极值的问题，这时候就会用求极值最常用的一种方法求偏导。\n",
    "\n",
    "![title](other/22.jpg)\n",
    "\n",
    "4. 反向传播，链式法则：\n",
    "\n",
    "* 现在我们就可以通过梯度对权重“w”进行更新使得Loss下降了，下图“θo”表示当前权重，“η”表示学习率，表示我们每次延负梯度下降的步长，每次下降多少，学习率“η”不能过大也不能太小，当学习率过大时，相当于我们的步子迈的太大了，会错过Loss最低值，当学习率太小时，我们就需要很长时间才能走到最低处，因此学习率需要设置得合理。因为我们需要往负梯度前进，因此需要在梯度值前面添加“-”负号。\n",
    "\n",
    "![title](other/23.jpg)\n",
    "\n",
    "* 然后只需要用当前权重“θo”减去学习率乘以当前梯度值就可以得到新的权重“θ”，当前的权重“θ”就会使得Loss往最小值前进一步了，当然Loss不会理想的一次就能到达最小值，因此我们就需要不断的更新我们的权重“θ”，因为在神经网络中是一个神经元连接另一个神经元，因此需要对每一个权重“θ”通过反向传播的方式进行更新，其中计算的方式就是通过链式法则对每一个权重“θ”进行求导。如下图，我们更新权重“z”是通过Loss对“z”求导，更新权重“x”是通过先对Loss对“z”求导乘以权重“z”对“x”求导；同理可以更新权重“y”。这就是链式法则原理。\n",
    "\n",
    "![title](other/link.jpg)\n",
    "\n",
    "* 最后通过不断迭代一直到loss很难下降时或者到达我们的预期值，就说明我们的模型就训练好了，因此我们观察模型训练时的一个重要指标就是Loss值，当然还有更直观的就是直接检测我们的模型，测试模型的准确率。\n",
    "\n",
    "* 看起来是不是很复杂，但是不用害怕，pytorch学习框架将这些逻辑已经写好了，我们只需要简单的几行代码他就可以自动进行求导计算并更新权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设置\n",
    "模型训练参数设置主要有:\n",
    "1. epoch:训练次数，一个epoch表示整个数据集训练一次，每训练一次我们的模型权重就会被更新一次，在这里我们使用的数据集为“train_min”，因此一个epoch的图片有200张。在训练时往往需要重复训练很多次才能训练出优秀的模型。在这个实验中我们只训练了20个epoch，这远远是不够的，但我们可以通过这个实验来学习到每个参数的作用，以及参数对模型的影响。\n",
    "2. learning_rate：学习率，学习率的设置需要根据不同的网络，不同的数据集来调整的，一般先给一个较大的学习率观察loss有没有下降，如果loss不下降或者一直来回的震荡，说明我们的学习率需要再调小一点，如果Loss下降\n",
    "\n",
    "3. optimizer:优化器，优化器的选择决定了我们以什么样的方式进行梯度下降。可以看到不同的优化器带来的效果也不同，有的会下降得很快但是没有到达最小值，有的很慢但可以到达最小值，因此在不同得情况中可以选择不同的优化器，在我们这个实验中我们采用的时“SGD”随机梯度下降。\n",
    "\n",
    "![title](other/optimizer.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(alex_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# 加载评估数据集，评估的数据集不需要打乱顺序。\n",
    "val_dir = '../../../models/local/datasets/cnn_teach/val'\n",
    "pre_val = preprosees(val_dir)\n",
    "val_loader = dataloader(pre_val, shuffle=False)\n",
    "\n",
    "# 设置模型保存路径和名称，因为我们使用的torch学习框架因此模型后缀基本都是“.pth”。\n",
    "min_MODEL_PATH = 'studens_models/mindata_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始定义模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练时需要依次输入训练次数，训练数据集，评估数据集，模型，优化器，模型保存路径。\n",
    "def train(epoch, train_loader, val_loader, model, optimizer, MODEL_PATH):\n",
    "    print('开始训练,请稍后!')\n",
    "    \n",
    "    # 初始化评估准确率\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    # 循环训练epoch次。\n",
    "    for epoch in range(epoch):\n",
    "        \n",
    "        # 初始化训练图片数量，当我们不清楚训练数据集有多少张图片时，可以自动计算图片数量，在下方我们可以用到。\n",
    "        image_count = 0.0\n",
    "        \n",
    "        # 从训练数据集加载器中加载图片，每次加载的数量为一个batch_size，通过iter()函数遍历每个batch_size。每个batch_size包含有\n",
    "        #预处理后的图片和通过onehot编码设置的标签。\n",
    "        model.train()\n",
    "        for images, labels in iter(train_loader):\n",
    " \n",
    "            # 如果有GPU就使用cuda加速，没有就使用cpu\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 将梯度归零，计算loss的时候是对Batch_size张图片的loss对权重“w”的导数的平均数，所以会有一个Batch_size张图片\n",
    "            #loss累加的计算的过程，这时候在计算新的导数的时候，是要进行一次清零才能计算新一轮Batch中Batch_size张图片的导数\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 将图片输入神经网络，得到输出结果\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 通过激活函数sigmoid将输出结果转化为概率值。\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "            # 通过交叉熵损失计算Loss损失值，输入真实值和预测值\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            \n",
    "            # 反向传播，对权重“w”求导，更新权重。\n",
    "            loss.backward()\n",
    "            \n",
    "            # 开始更新\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 自动计算图片数量\n",
    "            image_count+=len(images)\n",
    "        print('误差Loss：', loss.item())\n",
    "        \n",
    "        # 模型评估\n",
    "        # 初始化预测错误数量，评估数据集图片数量。\n",
    "        test_error_count = 0.0\n",
    "        images_count = 0.0\n",
    "        model.eval()\n",
    "        for images, labels in iter(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                # 将评估数据集输入网络，得出预测结果\n",
    "                outputs = model(images)\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            # 找到outputs的最大值的索引，例如输出为[0.85, 0.23],最大值为0.85，返回的索引就为0，就代表预测结果为类别0，概率为85%，\n",
    "            # 然后通过计算真实标签和预测结果索引的绝对值就可以计算出错误的数量了。\n",
    "            test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "            images_count += len(images)\n",
    "            \n",
    "        # 求出准确率\n",
    "        test_accuracy = round((1.0 - float(test_error_count) / images_count)*100, 2)\n",
    "        print('经过 {} 轮训练,准确率为：{}%'.format(epoch+1, test_accuracy))\n",
    "        \n",
    "        # 如果当前准确率大于之前的最高准确率就保存模型\n",
    "        if test_accuracy > best_accuracy:\n",
    "            # 保存模型\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            best_accuracy = test_accuracy\n",
    "            \n",
    "    print('训练完成！模型最高准确率为：{}%'.format(best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练\n",
    "* 在这里我们评估的数据集是通过训练数据集复制出来的50张“有小狗”的图片和50张“没有小狗”的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epoch, min_train_loader, val_loader, alex_model, optimizer, min_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集对模型的影响\n",
    "从上面可以看到随着不断的训练，Loss的变化很小，准确率也不是很高，这是为什么呢？\n",
    "其中一个很重要的原因就是和我们的数据集有关，对于人类来说，我们只需要看几张或者几十张图片就能记住一个物体了，但是对于机器学习来说，他可能需要成千上万的数据才能学到物体的关键特征，然而我们这里只提供了两个类别共400张图片，这是远远不够的。\n",
    "\n",
    "* 接下来就通过包含有500张“有小狗”的图片，和500张“没有小狗”的图片“train_max”数据集来进行训练，看我们训练的结果怎么样！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_dir = '../../../models/local/datasets/cnn_teach/train_max'\n",
    "pre_max_train = preprosees(max_train_dir)\n",
    "max_train_loader = dataloader(pre_max_train, shuffle=True)\n",
    "\n",
    "epoch = 20\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(alex_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "max_MODEL_PATH = 'studens_models/maxdata_model.pth'\n",
    "\n",
    "# 开始训练\n",
    "train(epoch, max_train_loader, val_loader, alex_model, optimizer, max_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集影响结论\n",
    "可以看到图片的数量对模型的影响是很大的，这里因为时间的限制只提供了1000张训练数据集，当我们数据量越大，训练时间就会越久，但是对于模型来说数据量越多模型的表现力就会更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试\n",
    "当我们的模型训练完成时，我们就可以通过“test”测试数据集来进行测试，这个数据集是一个新的数据集并且没有通过神经网络进行过训练。\n",
    "这个数据集有16张小狗的图片，我们可以通过测试来测试模型在识别它从没见过的图片的效果如何。\n",
    "* 首先还是需要对定义数据预处理，这里和训练时数据预处理不一样，因为我们这里需要手动添加图片，因此需要通过“opencv”打开图片，并且这里舍弃了对图片的颜色亮度等调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(x):\n",
    "    x = cv2.imread(x)\n",
    "    x = cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = np.ascontiguousarray(x, dtype=np.float32)\n",
    "    x = normalize(torch.from_numpy(x)).unsqueeze(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数输入模型和测试数据集路径。\n",
    "def test(alex_model,test_dir):\n",
    "    \n",
    "    #我们可以通过“matplotlib”模块中的“pyplot”方法将测试的结果用图片展示出来\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # os.listdir()遍历“test_dir”文件夹下所有的图片，返回图片名称。\n",
    "    img_names = os.listdir(test_dir)\n",
    "    \n",
    "    # 测试“test_dir”文件夹下所有的图片。\n",
    "    for i in range(len(img_names)):\n",
    "        \n",
    "        # os.path.join()将路径与文件名连接起来，返回路径加图片名称，这样我们网络才能读取到这张图片。\n",
    "        img_raw = os.path.join(test_dir, img_names[i])\n",
    "        \n",
    "        # 图片预处理。\n",
    "        img = preprocess(img_raw).to(device)\n",
    "        \n",
    "        # 测试时需要关闭梯度计算\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # 将图片输入模型，得出预测结果。\n",
    "            predict = alex_model(img)\n",
    "            predict = torch.sigmoid(predict)\n",
    "            \n",
    "            # 找到概率最大的索引值\n",
    "            predict = predict.argmax().data.cpu().numpy()\n",
    "            \n",
    "            # 找到对应索引的类别\n",
    "            predict = class_names[predict]\n",
    "            \n",
    "        # 用“matplotlib”将图片展示出来\n",
    "        plt.subplot(4,4, i+1)\n",
    "        img_raw = Image.open(img_raw)\n",
    "        img_raw = img_raw.resize((200,200))\n",
    "        #调整图片间距\n",
    "        plt.subplots_adjust(wspace=0.0, hspace=0.4)\n",
    "        plt.rcParams['font.sans-serif']=['SimHei']\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.title(predict)\n",
    "        plt.imshow(img_raw)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    print('预测结果如下：')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型进行预测\n",
    "* 首先加载通过“train_min”数据集训练得到的模型“mindata_model.pth”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试集路径\n",
    "test_dir = '../../../models/local/datasets/cnn_teach/test'\n",
    "\n",
    "# 加载我们训练完成的模型\n",
    "alex_model.load_state_dict(torch.load('studens_models/mindata_model.pth'))\n",
    "min_model = alex_model.to(device)\n",
    "\n",
    "# 开始预测\n",
    "test(min_model, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "* 可以看到神经网络对我们的小狗的识别准确率不是很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 下面加载通过“train_max”数据集训练得到的模型“maxdata_model.pth”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model.load_state_dict(torch.load('studens_models/maxdata_model.pth'))\n",
    "device = torch.device('cuda')\n",
    "max_model = alex_model.to(device)\n",
    "test(max_model, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过“train_max”数据集训练得到的模型是不是更加准确了呢，如果效果不是很好的话，你可以尝试增加训练次数，将“epoch”的值增加，或者可以增加训练数据集，然后重新训练，你可以看到你的新模型准确率会更高哦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "小狗识别",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
